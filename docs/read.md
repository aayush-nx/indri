Strongly suggested to read all papers of either google OR meta. 
Mixing may result in undesirable confusions. 
I personally prefer meta's stack because its open source with all code and models available to read and experiment with. 

Meta's audio work is available in https://github.com/facebookresearch/audiocraft

Google's in : https://google-research.github.io/seanet/

Audio Tokenization 
1. Encodec - meta
2. SoundStream - goog

Image / Video tokenization
1. Chameleon - meta
2. MagvitV2 - goog

Audio generation using tokens 
1. Bark - suno based on https://arxiv.org/pdf/2302.03540
2. Audiogen - meta
3. MultiBand diffusion - meta
4. Musicgen - meta
4. audiolm - goog [find more in the seanet page]