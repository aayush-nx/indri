{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef148c5-ab4d-499b-9651-c2e1e907dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from audiotoken import AudioToken, Tokenizers\n",
    "\n",
    "from tts.long_infer import AudioSemantic\n",
    "from tts.long_infer import generate as aco_generate\n",
    "from common import Config as cfg\n",
    "from common import ACOUSTIC, SEMANTIC, TEXT, ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d12e3-8d1c-42e9-aae3-e379bfe24dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttslib = AudioSemantic()\n",
    "acoustic_tokenizer = AudioToken(Tokenizers.acoustic, device='cuda:0')\n",
    "semantic_tokenizer = AudioToken(Tokenizers.semantic_s, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd630cda-dc14-4fc1-9084-519368bdfcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_consecutive(arr):\n",
    "    mask = np.concatenate(([True], arr[1:] != arr[:-1]))\n",
    "    return arr[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5cc98-4550-4660-8342-c4b3c0777144",
   "metadata": {},
   "source": [
    "Ready the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c193c7c-1fda-4965-a162-2b6b54f1a3e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt_aco_toks = acoustic_tokenizer.encode(Path('prompts/female_prompt_short.wav'))\n",
    "prompt_sem_toks = semantic_tokenizer.encode(Path('prompts/female_prompt_short.wav'))\n",
    "\n",
    "prompt_sem_toks = replace_consecutive(prompt_sem_toks[0][0])\n",
    "prompt_aco_toks.shape, prompt_sem_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbea42-e30f-42e1-8bf3-60ec9b4f4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_aco_toks = prompt_aco_toks[0, :2, :].clone()\n",
    "flat_aco_toks[1] += 1024\n",
    "flat_aco_toks = torch.stack([flat_aco_toks[0], flat_aco_toks[1]], dim=1).flatten()\n",
    "\n",
    "prompt_toks_dict = {\n",
    "    'source_tokens': prompt_sem_toks.numpy(),\n",
    "    'target_tokens': flat_aco_toks.numpy()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3871aa-2c58-4e56-ba06-4cfd3893f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "auds = acoustic_tokenizer.decode(prompt_aco_toks)\n",
    "Audio(auds[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2225e-1eb9-4074-98b1-55cc20047418",
   "metadata": {},
   "outputs": [],
   "source": [
    "aco_gen_toks = aco_generate(\n",
    "    model=ttslib.semantic_acoustic_model, \n",
    "    source_tokens=prompt_sem_toks.numpy(),\n",
    "    source=SEMANTIC,\n",
    "    target=ACOUSTIC\n",
    ")\n",
    "aco_gen_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b1ccd-c6d0-46ed-a248-1b9fc1d1a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation from original semantic tokens\n",
    "auds = ttslib.semantic_to_audio(prompt_sem_toks.numpy())\n",
    "Audio(auds[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de4ca8-ce1a-4335-b0c8-7742b704a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation from intermediatery 2 codebook\n",
    "auds = ttslib.acoustic_tokenizer.decode(torch.tensor(aco_gen_toks))\n",
    "Audio(auds[0], rate=24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3201bb3-aa51-485f-bb3e-03954b3e5de4",
   "metadata": {},
   "source": [
    "Long text, testing text to semantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a476b-a64d-406d-aecd-ede461e13bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = \"the breeze was gentle <comma> rustling the leaves of the trees as birds chirped softly in the distance <period>\"\n",
    "txt2 = \"it was a perfect evening to take a leisurely stroll <comma> letting the calmness of nature wash over you <period>\"\n",
    "txt3 = \"every step on the gravel path felt like a soothing rhythm <comma> matching the tranquility of the surroundings <period>\"\n",
    "txt4 = \"as the sky shifted from orange to deep purple <comma> the first stars began to appear <comma> twinkling like tiny diamonds in the vastness above <period>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2b6a8-7018-4aa5-a915-6a1ebdcdc580",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = \"our adventure began in paris <period>\"\n",
    "txt2 = \"the eiffel tower amazed us <period>\"\n",
    "txt3 = \"we enjoyed cafes and croissants <period>\"\n",
    "txt4 = \"the louvres art was stunning <period>\"\n",
    "txt5 = \"we ended in nice by the sea <period>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c254cd-f622-4ef3-8964-e551f921f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_toks = ttslib.text_to_semantic(' '.join([txt1, txt2, txt3, txt4, txt5]))\n",
    "print(sem_toks.shape, np.unique(sem_toks).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ba498-bb9c-4a9f-9d60-b6612d42957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_toks_diff = []\n",
    "for t in [txt1, txt2, txt3, txt4, txt5]:\n",
    "    s = ttslib.text_to_semantic(t)\n",
    "    sem_toks_diff.extend(s)\n",
    "    print(s.shape, replace_consecutive(s).shape)\n",
    "\n",
    "sem_toks_diff = np.array(sem_toks_diff)\n",
    "sem_toks_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090c3a2-e510-4699-9ae4-4648e408e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sem_toks)\n",
    "plt.hist(sem_toks_diff, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8ca9c-d0b6-4dbd-8ec6-44e6fd6438d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auds = []\n",
    "\n",
    "for i in range(5):\n",
    "    try:\n",
    "        aud = ttslib.semantic_to_audio(sem_toks_diff[150:300])\n",
    "        print(aud.shape)\n",
    "        auds.append(aud)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "for aud in auds:\n",
    "    display(Audio(aud[0], rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9179c-e011-4fdf-9320-2d2c847e10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_tokens = gen_new_prompt(\n",
    "    model=ttslib.text_semantic_model, \n",
    "    source_tokens=np.array(ttslib.text_tokenizer.encode(' '.join([txt1, txt2, txt3, txt4, txt5]))),\n",
    "    source=TEXT,\n",
    "    target=SEMANTIC,\n",
    "    prompt_dict=prompt_toks_dict,\n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "print(acoustic_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92849291-11f7-4dc9-b147-cb529826e8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc462de1-6ca5-4eb2-bc62-8ecd6c02fc9f",
   "metadata": {},
   "source": [
    "Legacy gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcf145-d48f-4360-a0fa-d8142c62de4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auds = []\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        aud = ttslib.semantic_to_audio_long(sem_toks)\n",
    "        print(aud.shape)\n",
    "        auds.append(aud)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168b3be-a0bf-47cc-8190-4d92cb9e1af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for aud in auds:\n",
    "    display(Audio(aud[0], rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31540c8-d996-4845-a5bf-99cf9389d49a",
   "metadata": {},
   "source": [
    "New gen (with conditioning and prompting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70c4c6-b92d-47ec-85f3-812e5edc8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new(model, source, target, source_tokens, device):\n",
    "    source_tokens = source_tokens + cfg.OFFSET[source]\n",
    "    max_source_tokens = cfg.max_source_tokens//2\n",
    "\n",
    "    source_overlap = 64\n",
    "    target_overlap = 0\n",
    "    source_stride = max_source_tokens - source_overlap\n",
    "\n",
    "    # Initialize as empty\n",
    "    target_tokens = np.asarray([])\n",
    "\n",
    "    print(\n",
    "        f'Source, tokens shape: {source_tokens.shape}, overlap: {source_overlap}, stride: {source_stride}, max tokens: {max_source_tokens}'\n",
    "    )\n",
    "\n",
    "    for idx in range(0, len(source_tokens), source_stride):\n",
    "        end_idx = idx + max_source_tokens\n",
    "        source_cut = source_tokens[idx: end_idx]\n",
    "        target_cut = target_tokens[-target_overlap:]\n",
    "\n",
    "        input_tokens = np.hstack([\n",
    "            source_cut,\n",
    "            cfg.INFER_TOKEN[target],\n",
    "            target_cut\n",
    "        ])\n",
    "\n",
    "        input_tokens = torch.tensor(input_tokens, dtype=torch.long, device=device)[None, ...]\n",
    "\n",
    "        print(f'Source tokens shape: {input_tokens.shape}, start idx: {idx}, end idx: {end_idx}')\n",
    "        print(f'Target cut shape: {target_cut.shape}, overlap: {target_overlap}')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with ctx:\n",
    "                new_target_tokens = model.generate(\n",
    "                    input_tokens,\n",
    "                    1024,\n",
    "                    temperature=0.8,\n",
    "                    top_k=100,\n",
    "                    stop_token=cfg.STOP_TOKEN[target]\n",
    "                ).detach().cpu().numpy()[0]\n",
    "                print(f'Gen shape: {new_target_tokens.shape}')\n",
    "\n",
    "        new_target_tokens = new_target_tokens[input_tokens.shape[-1]:]\n",
    "\n",
    "        # Update the target overlap ratio, for x toks, we generate y toks\n",
    "        num_source_new_toks = end_idx-idx\n",
    "        if idx:\n",
    "            num_source_new_toks = end_idx-idx-source_overlap\n",
    "        target_overlap = source_overlap * new_target_tokens.shape[-1]/num_source_new_toks\n",
    "        target_overlap = math.ceil(target_overlap)\n",
    "        target_overlap = target_overlap + 1 if target_overlap%2 != 0 else target_overlap\n",
    "        print(f'Source toks: {num_source_new_toks}, New target shape: {new_target_tokens.shape}, overlap: {target_overlap}')\n",
    "        # Merge into existing target tokens\n",
    "        target_tokens = np.hstack([target_tokens, new_target_tokens])\n",
    "        print(f'Overall target shape: {target_tokens.shape}')\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        if end_idx > source_tokens.shape[-1]:\n",
    "            break\n",
    "\n",
    "    target_tokens = target_tokens - cfg.OFFSET[target]\n",
    "    return target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc6e20-627e-45ef-b8c0-85935efa3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new_prompt(model, source, target, source_tokens, prompt_dict, device, source_overlap=64):\n",
    "    source_tokens = source_tokens + cfg.OFFSET[source]\n",
    "    max_source_tokens = cfg.max_source_tokens//2\n",
    "\n",
    "    prompt_source_tokens = prompt_toks_dict.get('source_tokens') + cfg.OFFSET[source]\n",
    "    prompt_target_tokens = prompt_toks_dict.get('target_tokens') + cfg.OFFSET[target]\n",
    "\n",
    "    print(f'Prompt source tokens: {prompt_source_tokens.shape}, prompt target tokens: {prompt_target_tokens.shape}')\n",
    "\n",
    "    source_overlap = source_overlap\n",
    "    target_overlap = 0\n",
    "    source_stride = max_source_tokens - source_overlap\n",
    "\n",
    "    # Initialize as empty\n",
    "    target_tokens = np.asarray([])\n",
    "\n",
    "    print(\n",
    "        f'Source tokens shape: {source_tokens.shape}, Overlap: {source_overlap}, stride: {source_stride}, max tokens: {max_source_tokens}\\n'\n",
    "    )\n",
    "\n",
    "    for idx in range(0, len(source_tokens), source_stride):\n",
    "        end_idx = idx + max_source_tokens\n",
    "        source_cut = source_tokens[idx: end_idx]\n",
    "        target_cut = target_tokens[-target_overlap:]\n",
    "\n",
    "        input_tokens = np.hstack([\n",
    "            source_cut,\n",
    "            cfg.INFER_TOKEN[target],\n",
    "            target_cut\n",
    "        ])\n",
    "\n",
    "        if idx == 0:\n",
    "            input_tokens = np.hstack([\n",
    "                prompt_source_tokens,\n",
    "                source_cut,\n",
    "                cfg.INFER_TOKEN[target],\n",
    "                prompt_target_tokens\n",
    "            ])\n",
    "\n",
    "        input_tokens = torch.tensor(input_tokens, dtype=torch.long, device=device)[None, ...]\n",
    "\n",
    "\n",
    "        print(f'{idx}: Target cut shape: {target_cut.shape}, overlap: {target_overlap}')\n",
    "        print(f'{idx}: Source tokens shape: {input_tokens.shape}, start idx: {idx}, end idx: {end_idx}')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with ctx:\n",
    "                new_target_tokens = model.generate(\n",
    "                    input_tokens,\n",
    "                    1024,\n",
    "                    temperature=0.8,\n",
    "                    top_k=100,\n",
    "                    stop_token=cfg.STOP_TOKEN[target]\n",
    "                ).detach().cpu().numpy()[0]\n",
    "                print(f'{idx}: Total gen shape: {new_target_tokens.shape}')\n",
    "\n",
    "        # Only take newly generated tokens\n",
    "        new_target_tokens = new_target_tokens[input_tokens.shape[-1]:]\n",
    "\n",
    "        if new_target_tokens.shape[-1] % 2 != 0:\n",
    "            print('breaking here')\n",
    "            return new_target_tokens\n",
    "\n",
    "        # Update the target overlap ratio, for x toks, we generate y toks\n",
    "        num_source_new_toks = end_idx-idx\n",
    "        if idx:\n",
    "            num_source_new_toks -= source_overlap\n",
    "        target_overlap = source_overlap * new_target_tokens.shape[-1]/num_source_new_toks\n",
    "        target_overlap = math.ceil(target_overlap)\n",
    "        target_overlap = target_overlap + 1 if target_overlap%2 != 0 else target_overlap\n",
    "\n",
    "        print(f'{idx}: X toks: {num_source_new_toks}, Y toks: {new_target_tokens.shape}, overlap: {target_overlap}')\n",
    "        # Merge into existing target tokens\n",
    "        target_tokens = np.hstack([target_tokens, new_target_tokens])\n",
    "        print(f'{idx}: Overall target shape is now: {target_tokens.shape}')\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        if end_idx > source_tokens.shape[-1]:\n",
    "            break\n",
    "\n",
    "    target_tokens = target_tokens - cfg.OFFSET[target]\n",
    "    return target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fdf55-e73c-42fb-9e71-bbd190b23b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acoustic_tokens = gen_new_prompt(\n",
    "    model=ttslib.semantic_acoustic_model, \n",
    "    source_tokens=sem_toks_diff,\n",
    "    source=SEMANTIC,\n",
    "    target=ACOUSTIC,\n",
    "    prompt_dict=prompt_toks_dict,\n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "print(acoustic_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11daa25e-d7f9-4c66-8969-35c90cd02ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "Audio(wav[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1526065-6703-4321-9f95-191cf9c4ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens[:-1]))\n",
    "wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "Audio(wav[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cc303-9d60-4da1-b63b-06f2a9c7be8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acoustic_tokens = gen_new(\n",
    "    model=ttslib.semantic_acoustic_model, \n",
    "    source_tokens=sem_toks_diff,\n",
    "    source=SEMANTIC,\n",
    "    target=ACOUSTIC,\n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "print(acoustic_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48a123-d3e1-494a-8415-ccb50402f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "Audio(wav[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e649e06-adce-4342-9bc6-8454fc9d2ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d94eb3-a8b5-4243-84a9-341b9bfc0614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
