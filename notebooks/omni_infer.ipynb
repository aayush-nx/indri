{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb01061-a261-43bf-90db-32de75f0def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.cuda import empty_cache\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from configs.commons import Config as cfg\n",
    "from configs.commons import DEVICE, CACHE_DIR, CTX\n",
    "from configs.constants import *\n",
    "\n",
    "from omni.hfload import convert_to_hf\n",
    "from datalib.tokenlib import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14dadda-2de6-4fc4-9527-5f422a1415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9e3e9-d437-4224-8214-b3e379571f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "omni_model = convert_to_hf(path=f'/home/.cache/indri/models/omni_tasks_large/gpt_2900.pt', device=DEVICE)\n",
    "semantic_acoustic_model = convert_to_hf(path=f'/home/.cache/indri/romit/models/semantic_acoustic_tasks_small/gpt_4500.pt', device=DEVICE)\n",
    "\n",
    "text_tokenizer = get_tokenizer(TEXT, device='cpu')\n",
    "acoustic_tokenizer = get_tokenizer(ACOUSTIC, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286150f1-2bd7-4501-9579-4dad35818769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(cfg.VOCAB_SIZES[SEMANTIC]):\n",
    "    text_tokenizer.tokenizer.add_tokens(f'[sem_{idx}]')\n",
    "\n",
    "for idx in range(cfg.VOCAB_SIZES[ACOUSTIC]):\n",
    "    text_tokenizer.tokenizer.add_tokens(f'[aco_{idx}]')\n",
    "\n",
    "for tok in list(cfg.MODALITY_TOKENS.values()) + list(cfg.TASK_TOKENS.values()) + [cfg.STOP_TOKEN]:\n",
    "    print('Adding token: ', tok)\n",
    "    text_tokenizer.tokenizer.add_tokens(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957027e1-a3d1-4c02-a8c4-a15f9bdcdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_token = text_tokenizer.encode(cfg.TASK_TOKENS[CONVERT])\n",
    "continue_token = text_tokenizer.encode(cfg.TASK_TOKENS[CONTINUE])\n",
    "stop_token = text_tokenizer.encode(cfg.STOP_TOKEN)\n",
    "semantic_modality_token = text_tokenizer.encode(cfg.MODALITY_TOKENS[SEMANTIC])\n",
    "acoustic_modality_token = text_tokenizer.encode(cfg.MODALITY_TOKENS[ACOUSTIC])\n",
    "text_modality_token = text_totemp_sem_tokskenizer.encode(cfg.MODALITY_TOKENS[TEXT])\n",
    "speaker_id = text_tokenizer.encode(\"[spkr_unk]\")\n",
    "\n",
    "omni_model.generation_config.eos_token_id = stop_token\n",
    "semantic_acoustic_model.generation_config.eos_token_id = stop_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369d504-343c-4a6f-bf71-d606f4fe0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_txt = \"once upon a time there was a girl named emily\"\n",
    "txt_toks = np.array(text_tokenizer.encode(random_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5e3e6-c425-4020-8bfe-b2508d491d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = np.hstack([\n",
    "    text_modality_token,\n",
    "    txt_toks,\n",
    "    convert_token,\n",
    "    semantic_modality_token,\n",
    "    speaker_id,\n",
    "])\n",
    "input_tokens = (torch.tensor(input_tokens, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(f'Text tokens: {input_tokens.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc02358-fd60-4be0-af1a-d881a8b16277",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = np.hstack([\n",
    "    semantic_modality_token,\n",
    "    speaker_id,\n",
    "    temp_sem_toks,\n",
    "    convert_token,\n",
    "    text_modality_token,\n",
    "])\n",
    "input_tokens = (torch.tensor(input_tokens, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(f'Text tokens: {input_tokens.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834de7d-c4fa-4d7a-946d-6a8f8c2971ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer.decode(input_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5eea31-d267-494d-9556-2cc8cb3312d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CTX:\n",
    "    semantic_tokens = omni_model.generate(\n",
    "        input_tokens,\n",
    "        max_length=1024,\n",
    "        temperature=0.7,\n",
    "        top_k=100,\n",
    "        do_sample=True\n",
    "    )\n",
    "    semantic_tokens = semantic_tokens.detach().cpu().numpy()[0]\n",
    "    semantic_tokens = semantic_tokens[input_tokens.shape[-1]:]\n",
    "    print(semantic_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cc471-5715-4331-a2f5-22c0a46cb0d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "semantic_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf61d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer.decode(semantic_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532b73b-c421-43b5-ab07-ec51d6824970",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx = np.where(semantic_tokens == stop_token)[0][0]\n",
    "semantic_tokens = semantic_tokens[0:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc87f16-6105-486a-88eb-7c28faf3c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_tokens = np.hstack([\n",
    "    semantic_modality_token,\n",
    "    speaker_id,\n",
    "    semantic_tokens,\n",
    "    convert_token,\n",
    "    acoustic_modality_token,\n",
    "    speaker_id,\n",
    "])\n",
    "semantic_tokens = (torch.tensor(semantic_tokens, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(f'Semantic tokens: {semantic_tokens.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f4e4d-aedf-4d2b-94dd-b97b651ad8bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CTX:\n",
    "    acoustic_tokens = semantic_acoustic_model.generate(\n",
    "        semantic_tokens,\n",
    "        max_length=3072,\n",
    "        temperature=0.9,\n",
    "        top_k=100,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    acoustic_tokens = acoustic_tokens.detach().cpu().numpy()[0]\n",
    "    acoustic_tokens = acoustic_tokens[semantic_tokens.shape[-1]:]\n",
    "    print(acoustic_tokens.shape)\n",
    "\n",
    "end_idx = np.where(acoustic_tokens == stop_token)[0][0]\n",
    "acoustic_tokens = acoustic_tokens[0:end_idx]\n",
    "acoustic_tokens = acoustic_tokens - cfg.OFFSET[ACOUSTIC]\n",
    "\n",
    "if len(acoustic_tokens) % 2 == 1:\n",
    "    acoustic_tokens = acoustic_tokens[:-1]\n",
    "\n",
    "print(f'Acoustic tokens: {acoustic_tokens.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a64d2-a77d-4f02-ab19-ebb6e9abff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "wav = wav[0].cpu().numpy()\n",
    "Audio(wav, rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936495a-68b6-4e5f-9981-ec34a59f7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = text_tokenizer.encode(\"[spkr_jenny]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8b497-b85c-4c07-b620-bf7f93dd1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing with custom tokens\n",
    "prompt = np.load('../prompts/jenny_short/tokens.npz')\n",
    "temp_sem_toks = prompt['SEMANTIC']\n",
    "temp_sem_toks += cfg.OFFSET[SEMANTIC]\n",
    "# temp_sem_toks = np.hstack([\n",
    "#     semantic_modality_token,\n",
    "#     speaker_id,\n",
    "#     temp_sem_toks,\n",
    "#     convert_token,\n",
    "#     acoustic_modality_token,\n",
    "#     speaker_id,\n",
    "# ])\n",
    "# temp_sem_toks = (torch.tensor(temp_sem_toks, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(temp_sem_toks.shape)\n",
    "\n",
    "# speaker_id = text_tokenizer.encode(\"[spkr_jenny]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a3936-390c-4862-ad43-6015d611842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer.decode(temp_sem_toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34eacf-64fb-46f1-b631-97c77fb7fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_consecutive(arr):\n",
    "    mask = np.concatenate(([True], arr[1:] != arr[:-1]))\n",
    "    return arr[mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
