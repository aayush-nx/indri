{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb01061-a261-43bf-90db-32de75f0def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.cuda import empty_cache\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from configs.commons import Config as cfg\n",
    "from configs.commons import DEVICE, CACHE_DIR, CTX\n",
    "from configs.constants import *\n",
    "\n",
    "from omni.hfload import convert_to_hf\n",
    "from datalib.tokenlib import get_tokenizer\n",
    "from omni.train_omni_instruct import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14dadda-2de6-4fc4-9527-5f422a1415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9e3e9-d437-4224-8214-b3e379571f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "omni_model = convert_to_hf(path=f'/home/.cache/indri/models/omni_tasks_large_full_sprk/gpt_13000.pt', device=DEVICE)\n",
    "semantic_acoustic_model = convert_to_hf(path=f'/home/.cache/indri/models/semantic_acoustic_tasks_spkr/gpt_26500.pt', device=DEVICE)\n",
    "\n",
    "text_tokenizer = get_tokenizer(TEXT, device='cpu')\n",
    "acoustic_tokenizer = get_tokenizer(ACOUSTIC, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056d074-ccdd-4870-8fed-15cfa566b12a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    interleaved_dirs=[],\n",
    "    datasets_dirs=[],\n",
    "    speaker_files=[Path('../allowed_speakers.jsonl').resolve()]\n",
    ")\n",
    "\n",
    "text_tokenizer = dl.text_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67674422-72d8-4ef5-a13a-90e2e9bc2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_model.generation_config.eos_token_id = dl.stop_token\n",
    "semantic_acoustic_model.generation_config.eos_token_id = dl.stop_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d59eb-469e-4a9f-b6af-4120906068dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = text_tokenizer.encode(\"[spkr_unk]\")\n",
    "acoustic_modality_token = text_tokenizer.encode(cfg.MODALITY_TOKENS[ACOUSTIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369d504-343c-4a6f-bf71-d606f4fe0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_txt = \"once upon a time there was a girl named emily\"\n",
    "txt_toks = np.array(text_tokenizer.encode(random_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5e3e6-c425-4020-8bfe-b2508d491d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = np.hstack([\n",
    "    dl.text_modality_token,\n",
    "    txt_toks,\n",
    "    dl.convert_token,\n",
    "    dl.semantic_modality_token,\n",
    "    speaker_id,\n",
    "])\n",
    "input_tokens = (torch.tensor(input_tokens, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(f'Text tokens: {input_tokens.shape}')\n",
    "text_tokenizer.decode(input_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc02358-fd60-4be0-af1a-d881a8b16277",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = np.hstack([\n",
    "    dl.semantic_modality_token,\n",
    "    speaker_id,\n",
    "    temp_sem_toks,\n",
    "    dl.convert_token,\n",
    "    dl.text_modality_token,\n",
    "])\n",
    "input_tokens = (torch.tensor(input_tokens, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(f'Text tokens: {input_tokens.shape}')\n",
    "text_tokenizer.decode(input_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5eea31-d267-494d-9556-2cc8cb3312d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CTX:\n",
    "    semantic_tokens = omni_model.generate(\n",
    "        input_tokens,\n",
    "        max_length=1024,\n",
    "        temperature=0.8,\n",
    "        top_k=100,\n",
    "        do_sample=True\n",
    "    )\n",
    "    semantic_tokens = semantic_tokens.detach().cpu().numpy()[0]\n",
    "    semantic_tokens = semantic_tokens[input_tokens.shape[-1]:]\n",
    "    print(semantic_tokens.shape)\n",
    "\n",
    "text_tokenizer.decode(semantic_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532b73b-c421-43b5-ab07-ec51d6824970",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx = np.where(semantic_tokens == dl.stop_token)[0][0]\n",
    "semantic_tokens = semantic_tokens[0:end_idx]\n",
    "print(semantic_tokens.shape)\n",
    "text_tokenizer.decode(semantic_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc87f16-6105-486a-88eb-7c28faf3c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_tokens = np.hstack([\n",
    "    dl.semantic_modality_token,\n",
    "    speaker_id,\n",
    "    semantic_tokens,\n",
    "    dl.convert_token,\n",
    "    acoustic_modality_token,\n",
    "    speaker_id,\n",
    "])\n",
    "semantic_tokens = (torch.tensor(semantic_tokens, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(f'Semantic tokens: {semantic_tokens.shape}')\n",
    "dl.text_tokenizer.decode(semantic_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f4e4d-aedf-4d2b-94dd-b97b651ad8bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CTX:\n",
    "    acoustic_tokens = semantic_acoustic_model.generate(\n",
    "        semantic_tokens,\n",
    "        max_length=3072,\n",
    "        temperature=0.8,\n",
    "        top_k=100,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    acoustic_tokens = acoustic_tokens.detach().cpu().numpy()[0]\n",
    "    acoustic_tokens = acoustic_tokens[semantic_tokens.shape[-1]:]\n",
    "    print(acoustic_tokens.shape)\n",
    "\n",
    "dl.text_tokenizer.decode(acoustic_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb302526-204e-4ba9-8798-017e0092b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx = np.where(acoustic_tokens == dl.stop_token)[0][0]\n",
    "acoustic_tokens = acoustic_tokens[0:end_idx]\n",
    "acoustic_tokens = acoustic_tokens - cfg.OFFSET[ACOUSTIC]\n",
    "\n",
    "if len(acoustic_tokens) % 2 == 1:\n",
    "    acoustic_tokens = acoustic_tokens[:-1]\n",
    "\n",
    "print(f'Acoustic tokens: {acoustic_tokens.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a64d2-a77d-4f02-ab19-ebb6e9abff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "wav = wav[0].cpu().numpy()\n",
    "Audio(wav, rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d02c0-9fdc-4bd0-8357-c8c7aaffde75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299fc86-c546-42a5-8cdd-1e19451a8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ced352-d648-4875-a584-15c3943639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save('jenny_7k_sem_aco.wav', torch.from_numpy(wav), sample_rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8b497-b85c-4c07-b620-bf7f93dd1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing with custom tokens\n",
    "speaker_id = text_tokenizer.encode(\"[spkr_unk]\")\n",
    "\n",
    "prompt = np.load('../prompts/lj_female_long/tokens.npz')\n",
    "temp_sem_toks = prompt['SEMANTIC'].astype(np.int64)\n",
    "# temp_sem_toks = prompt\n",
    "temp_sem_toks += cfg.OFFSET[SEMANTIC]\n",
    "temp_sem_toks = np.hstack([\n",
    "    dl.semantic_modality_token,\n",
    "    speaker_id,\n",
    "    temp_sem_toks,\n",
    "    dl.convert_token,\n",
    "    acoustic_modality_token,\n",
    "    speaker_id,\n",
    "])\n",
    "temp_sem_toks = (torch.tensor(temp_sem_toks, dtype=torch.long, device=DEVICE)[None, ...])\n",
    "print(temp_sem_toks.shape)\n",
    "\n",
    "text_tokenizer.decode(temp_sem_toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d370a7-0709-4f7b-83b6-05d4d1ef7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt  = np.load('/home/.cache/indri/data/gs_xl_en_tokens/tokens/text/YOU0000013586_S0000067.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b885bb9-63b1-4647-956c-7c9a32b5fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer.decode(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a3936-390c-4862-ad43-6015d611842d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34eacf-64fb-46f1-b631-97c77fb7fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_consecutive(arr):\n",
    "    mask = np.concatenate(([True], arr[1:] != arr[:-1]))\n",
    "    return arr[mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
