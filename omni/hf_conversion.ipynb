{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ce560-8187-4a18-a8ba-f643b12d4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "from tts.gpt2_model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a68f6-306f-4679-b9e4-5b1b9c6ef31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    print(path)\n",
    "    model = get_model(\n",
    "        vocab_size=53376,\n",
    "        device='cpu',\n",
    "        compile=False,\n",
    "        path=path\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a081b2-7f34-4c40-b576-79f55a85b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_gpt_path = '/home/romit/Desktop/meraki/hf_hub/audiotoken/semantic_detokenizer/semantic_s/hubert_semantic_acoustic_gpt_en.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ecff4-c90e-45b2-ad08-f03f1449df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_gpt_config = torch.load(custom_gpt_path, map_location='cpu')['config']\n",
    "custom_gpt = torch.load(custom_gpt_path, map_location='cpu')['model']\n",
    "\n",
    "custom_m = load_model(custom_gpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7cea5-fd08-47bf-9a61-d95d626891d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size = 53376,\n",
    "    n_positions = 1024,\n",
    "    n_embd = 768,\n",
    "    n_layer = 12,\n",
    "    n_head = 12,\n",
    "    use_bias=False,\n",
    "    dropout=0,\n",
    "    attn_pdrop=0,\n",
    "    embd_pdrop=0,\n",
    "    resid_pdrop=0,\n",
    "    summary_first_dropout=0,\n",
    "    activation_function='gelu'\n",
    ")\n",
    "\n",
    "hf_gpt = GPT2LMHeadModel(config).state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34352e83-5520-4cda-847a-9a65692f9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in hf_gpt.items():\n",
    "    if '.bias' in k:\n",
    "        assert v.sum() == 0, f'Sum is not zero for {k}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996e515-752b-4a49-80cb-cb87b4754eb9",
   "metadata": {},
   "source": [
    "1. Remove unwanted prefix\n",
    "2. Remove bias\n",
    "3. Transpose certain layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13430d99-e6db-4504-9a4a-49a2b4093f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_custom_gpt = {}\n",
    "\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k, v in custom_gpt.items():\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        clean_custom_gpt[k[len(unwanted_prefix):]] = custom_gpt[k]\n",
    "\n",
    "transposed = [\n",
    "    'attn.c_attn.weight', \n",
    "    'attn.c_proj.weight',\n",
    "    'mlp.c_fc.weight',\n",
    "    'mlp.c_proj.weight'\n",
    "]\n",
    "\n",
    "for k, v in clean_custom_gpt.items():\n",
    "    if any(k.endswith(w) for w in transposed):\n",
    "        clean_custom_gpt[k] = clean_custom_gpt[k].t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c173b96-c9a3-4f98-80b0-e3a3a2133a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model.load_state_dict(clean_custom_gpt, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe61c8-0e30-4d7d-90d9-51dbbe9e29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_hf = {}\n",
    "store_custom = {}\n",
    "\n",
    "def hook(module, input, output, name, store):\n",
    "    store[name] = output\n",
    "\n",
    "def register_hook(m, store):\n",
    "    for name, layer in m.named_modules():\n",
    "        layer.register_forward_hook(lambda layer, input, output, name=name: hook(layer, input, output, name, store))\n",
    "\n",
    "register_hook(model, store_hf)\n",
    "register_hook(custom_m, store_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930cc812-420f-4a47-aeee-0949f46beba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randint(0, 50000, (1, 100))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pretrained_out = model(inputs)\n",
    "    custom_out = custom_m(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ce8a9-5086-4084-b339-cca01450a302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in store_hf.items():\n",
    "   if k not in store_custom:\n",
    "       print(f'{k} not found in custom')\n",
    "   else:\n",
    "       if k == 'lm_head':\n",
    "           break\n",
    "       val1 = v\n",
    "       if type(val1) == tuple:\n",
    "            val1 = v[0]\n",
    "\n",
    "       val2 = store_custom[k]\n",
    "       if type(val2) == tuple:\n",
    "           val2 = val2[0]\n",
    "\n",
    "       diff = val1 - val2\n",
    "       diff = diff.abs()\n",
    "       diff = diff.max()\n",
    "       print(f'{k}\\t\\t\\t\\t{diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621c3a9-88a3-4cff-bac6-8105ccd29023",
   "metadata": {},
   "outputs": [],
   "source": [
    "(v[:, -1, :] - store_custom[k]).abs().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3217a7-3dc4-4738-b542-cad108a6e02d",
   "metadata": {},
   "source": [
    "Testing generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1541c4-a90f-4a6a-89b5-0f6611ff98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tts.infer import AudioSemantic\n",
    "\n",
    "from pathlib import Path\n",
    "from audiotoken import AudioToken, Tokenizers\n",
    "\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd36ec3-3968-4f61-9954-7737608caf8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "semlib = AudioSemantic(size='125m')\n",
    "semantic_tokenizer = AudioToken(Tokenizers.semantic_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee6aed-1282-46d9-b505-6a461b9250c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = semlib.text_to_semantic('my name is romit jain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd07b8c-384e-4f40-a76e-2dc591c197e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_toks = semantic_tokenizer.encode(Path('/home/romit/Downloads/audio/sent_3.wav'))\n",
    "sem_toks = sem_toks[0][0].reshape(-1, ).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f7c60-2a09-4a7a-8314-2cef8d12ec8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wav = semlib.semantic_to_audio(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29db92-b8dd-42be-965d-8df7c3e76e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(wav, rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a8dab-2d93-41f2-9597-6c3f4602b1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
